- [Redis](#redis)
  - [简单动态字符串SDS](#简单动态字符串sds)
  - [链表](#链表)
  - [字典](#字典)
    - [rehash的操作](#rehash的操作)
  - [跳表](#跳表)
  - [整数集合](#整数集合)
  - [压缩列表 ziplist](#压缩列表-ziplist)
- [对象](#对象)
  - [对象的类型和编码](#对象的类型和编码)
    - [字符串对象](#字符串对象)
    - [列表对象](#列表对象)
    - [哈希对象](#哈希对象)
    - [集合对象](#集合对象)
    - [有序集合对象](#有序集合对象)
      - [zset的使用场景](#zset的使用场景)
  - [对象的特点](#对象的特点)
    - [类型检查与命令多态](#类型检查与命令多态)
    - [内存回收](#内存回收)
    - [对象共享](#对象共享)
    - [LRU属性](#lru属性)
- [Redis持久化](#redis持久化)
  - [RDB持久化](#rdb持久化)
    - [RDB文件的创建与载入](#rdb文件的创建与载入)
    - [自动保存](#自动保存)
    - [RDB文件结构](#rdb文件结构)
  - [AOF持久化](#aof持久化)
    - [AOF持久化的实现](#aof持久化的实现)
    - [AOF重写](#aof重写)
  - [4.0的混合持久化](#40的混合持久化)
- [redis事件](#redis事件)
    - [文件事件](#文件事件)
    - [时间事件](#时间事件)
- [Redis多机数据库](#redis多机数据库)
    - [全量复制](#全量复制)
  - [增量复制](#增量复制)
    - [PSYNC](#psync)
    - [复制的实现](#复制的实现)
  - [心跳检测](#心跳检测)
- [Redis Sentinel哨兵模式](#redis-sentinel哨兵模式)
    - [启动并且初始化Sentinel](#启动并且初始化sentinel)
  - [故障检测与处理](#故障检测与处理)
- [Redis集群](#redis集群)
  - [节点](#节点)
  - [槽指派](#槽指派)
  - [命令执行](#命令执行)
  - [重新分片](#重新分片)
  - [ASK错误](#ask错误)
  - [复制与故障转移](#复制与故障转移)
    - [故障检测](#故障检测)
    - [故障转移](#故障转移)
    - [选举主节点的方法](#选举主节点的方法)
  - [消息](#消息)
- [缓存击穿、缓存穿透与缓存雪崩](#缓存击穿缓存穿透与缓存雪崩)
  - [缓存穿透](#缓存穿透)
  - [缓存击穿](#缓存击穿)
  - [缓存雪崩](#缓存雪崩)
  - [布隆过滤器](#布隆过滤器)
- [缓存更新策略(Redis和Mysql的一致性)](#缓存更新策略redis和mysql的一致性)
  - [存在问题的几种缓存更新问题](#存在问题的几种缓存更新问题)
- [redis事务](#redis事务)
  - [WATCH命令（乐观锁）](#watch命令乐观锁)
  - [ACID性质](#acid性质)
- [Redis的使用场景](#redis的使用场景)
  - [分布式锁](#分布式锁)
    - [可重入性](#可重入性)
    - [锁冲突](#锁冲突)
  - [异步消息队列](#异步消息队列)
    - [消费队列](#消费队列)
    - [延时队列](#延时队列)
    - [如何唤醒一个延迟任务](#如何唤醒一个延迟任务)
  - [缓存](#缓存)
  - [全局id，计数器，限流](#全局id计数器限流)
  - [位统计](#位统计)
  - [点赞签到打卡](#点赞签到打卡)
  - [点赞排行](#点赞排行)
- [其他问题](#其他问题)
  - [为什么要用Redis](#为什么要用redis)
  - [发布与订阅](#发布与订阅)
- [Redis数据库](#redis数据库)
  - [读写键空间时的维护操作](#读写键空间时的维护操作)
  - [键的生存过期时间](#键的生存过期时间)
  - [缓存过期策略](#缓存过期策略)
  - [AOF，RDB和复制对过期键的处理](#aofrdb和复制对过期键的处理)
  - [Redis的LRU （内存淘汰机制）](#redis的lru-内存淘汰机制)
    - [Redis LRU策略分类](#redis-lru策略分类)
    - [近似LRU优化](#近似lru优化)
  - [设计微信点赞](#设计微信点赞)

# Redis
五种对外的数据结构，六种内部的基础数据结构。

首先需要明确，**redis有五种类型的对象（基础数据结构）：字符串对象、列表对象、哈希对象、集合对象和有序集合对象。**

对内有6种数据结构实现这个基本类型：SDS，Dict，List，IntSet，ZipList，SkipList.


## 简单动态字符串SDS
SDS时redis的默认字符串表示，除了被用来保存数据库的字符串值之外，还被用于缓冲区：AOF缓冲区和客户端状态的输入缓冲区。Redis只会使用C字符串作为字面量。

> 基本结构

```c++
struct sdsdhr{
	int len; // 已经使用的字节长度
	int free; // 未使用的字节数量
	char buf[]; // 字节数组，实际用来保存字节。最后一个字节保存空字符，但是这个位置不计算为长度。
}
```

* 设计优点

1. 可以**常数复杂度**获得字符串长度，`STRLEN`复杂度为$O(1)$；**杜绝缓存区溢出**，优先比较拼接的字符串和当前的剩余空间的大小。
2. 采用**空间预分配和惰性空间释放两个方法优化内存分配**。
	* 空间预分配：小于1MB时候，再需要分配空间时候，会额外分配空间，使得len=free；大于1MB会额外给1MB空间。
	* 惰性空间释放：程序并无主动收回空余的空间。
3. **二进制安全**，不使用/0作为结束标志，而是len；兼容C字符串函数

## 链表
应用广泛，列表键的底层实现之一就是链表。还有**发布与订阅，慢查询等都是链表。**

**双端，无环，含有头尾指针**，还带有长度计数器和多态性质（可以保存不同类型的值）

> 基本结构
```java
// quicklist节点定义 --quicklist.h
typedef struct quicklistNode {
    struct quicklistNode *prev;     /* 前驱指针 */
    struct quicklistNode *next;     /* 后驱指针 */
    unsigned char *zl;              /* ziplist */
    unsigned int sz;                /* ziplist的bytes大小*/
    unsigned int count : 16;        /* ziplist中的元素数量 */
    unsigned int encoding : 2;      /* 是否进行LZF压缩 RAW==1 or LZF==2 */
    unsigned int container : 2;     /* 是否包含ziplist NONE==1 or ZIPLIST==2 */
    unsigned int recompress : 1;    /* 是否曾被压缩 */
    unsigned int attempted_compress : 1; /* 测试使用字段 */
    unsigned int extra : 10;        /* 预留内存空间 */
} quicklistNode;

// quicklist定义 --quicklist.h
typedef struct quicklist {
    quicklistNode *head;        /* 头节点指针 */
    quicklistNode *tail;        /* 尾节点指针 */
    unsigned long count;        /* 元素总数（所有ziplist中的所有元素） */
    unsigned long len;          /* quicklist节点数 */
    int fill : 16;              /* 节点的填充因子 */
    unsigned int compress : 16; /* LZF算法的压缩深度; 0=off */
} quicklist;
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020112217234797.png#pic_center)



## 字典
> 基本结构
table属性是一个数组，数组中每个元素都是一个指向dictEntry结构的指针，每个dictEntry结构保存着一个键值对。

**字典包括两个哈希表，一般字典只使用ht[0]哈希表，只有在rehash时候才会使用ht[1]**。rehash记录了当前的进度，如果没有进行重新哈希，为-1。hash算法用的MurmurHash2，得到的哈希值再与mask与得到index。

解决哈希冲突用**拉链法，并且新的节点总是被加在链表头$O(1)$**。
```java
// 哈希表dict具体结构定义 --dict.h
typedef struct dictht {
    dictEntry **table;                  /* 二维结构 数组+链表 ，表明了拉链法解决hash冲突*/
    unsigned long size;                 /* table[]大小 */
    unsigned long sizemask;             /* table[]大小的掩码 size-1（用以计算索引值）总是等于size-1 */
    unsigned long used;                 /* 已有节点个数 */
} dictht;

// dict中的节点定义 --dict.h
typedef struct dictEntry {
    void *key;                  /* 节点的键 */
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;                        /* 节点的值 */
    struct dictEntry *next;     /* 指针链接到下一个节点 */
} dictEntry;

// dict定义 --dict.h
typedef struct dict {
   dictType *type;                 /* 保存私有方法的对象指针 */
   void *privdata;                 /* 私有数据 */
   dictht ht[2];                   /* 每个dict包含两个dictht，用来rehash */
   long rehashidx;                 /* 执行rehash的索引，没有rehash时为-1 */
   unsigned long iterators;        /* 运行时的迭代器数 */
} dict;
```

### rehash的操作
每次扩展空间都是变为`ht[0].used*2`之后的第一个2次幂，减少是大于变为`ht[0].used`的2次幂。

当服务器没有执行`BGSAVE`时候，负载因子大于等于1开始扩容，否则大于5。负载因子定义为：.used/.size; 缩小的负载因子是0.1。

在扩展或者收缩时，采用的**渐进式哈希**，避免了rehash 的巨大计算量，因为是渐进式的哈希，数据的迁移并不是一步完成的，所以需要有一个索引来指示当前的rehash进度。当rehashidx为-1时，代表没有哈希操作。具体如下：

1. 为ht[1]开辟空间，rehashidx赋值0，开始从`*table[0]`开始将ht[0]的数据rehash至ht[1]
2. 随着rehashidx自增，对table[rehashidx]进行rehash，相当于数据的迁移。**在rehash期间，对disc的读操作会同时作用于ht[0]和ht[1]，写操作只会ht[1]**
3. ht[0]的数据全部rehash至ht[1]时，rehash完成。rehashidx赋值-1。
4. 将ht[1]赋值给ht[0]，清空ht[1]。

[rehash的流程](https://blog.csdn.net/makesifriend/article/details/92689343)

rehash是以bucket(桶)为基本单位进行渐进式的数据迁移的，每步完成一个bucket的迁移，直至所有数据迁移完毕。一个**bucket对应哈希表数组中的一条entry链表**。新版本的dictRehash()还加入了一个最大访问空桶数(empty_visits)的限制来进一步减小可能引起阻塞的时间。

如果hash表中的entry比较多的话，一次完成rehash需要耗费大量的时间，阻塞其它函数操作。redis中设定在执行add、delete、find操作时，执行一次**dictRehash(d,1)**。


## 跳表
**支持平均$O(logn)$，最坏$O(N)$复杂度的节点查找**。是**有序集合键**的底层实现之一。**每个节点的层高是1-32之间的随机数**。

前进可以跨越式前进，但是后退只有单一的步长。

> 基本结构
由两个类组成，类似链表。在同一个跳表中，每个节点保存的**成员对象必须是唯一，但是分数可以不必**，相同分数按照成员字典序排序。
```java
// skiplist定义 --server.h
typedef struct zskiplist {
    struct zskiplistNode *header, *tail;        /* skiplist的头、尾节点 */
    unsigned long length;                       /* 跳跃表长度/节点数（不包括头节点）、也就是元素数量 */
    int level;                                  /* 目前跳表层数最大的节点的层数，表头不算 */
} zskiplist;

// skiplist节点定义 --server.h
typedef struct zskiplistNode {
    robj *obj;                        /* 成员对象 */
    double score;                   /* 节点的分数,所有节点按照分数排序 */
    struct zskiplistNode *backward; /* 后退指针 */
    struct zskiplistLevel {
        struct zskiplistNode *forward;          /* 链接层与层的前驱指针 */
        unsigned long span;                     /* 路径跨度，搜索元素时累加span可得到rank排名 */
    } level[];                      /* skiplist的层 ，每层具有前进指针和跨度两个属性*/
} zskiplistNode;
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201122174955763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)


> 结构特点
可以进行快速的查询，并且因为是排序的，可以按照**分值范围进行查询**等操作。

## 整数集合
是集合键的底层实现之一，当一个集合只包含整数值元素，并且在几个元素数量不多时，redis采用整数集合作为集合键的底层实现。

> 基本结构
保存的是不会重复的元素，并且可以不同的大小。contents是底层实现，各项在数组中按照大小顺序从小到大有序排列。每个节点可以保存一个节点数组或者整数值。

```java
typedef struct intset{
	uint32_t encoding; // 编码方式int16_t,int32_t,int64_t
	uint32_t length; // 集合包含的元素数量
	int8_t contents[];	// 保存元素的数组
}intest;
```

>结构特点
* 升级与降级：
 当新加入的元素比数组元素类型长，整个整数集合要进行升级。数组进行扩容，所有元素都转化为与新元素相同的类型，保证数组的有序性不发生改变。因此向整数集合添加新元素的时间复杂度为$O(N)$。需要注意的是，**整数集合不支持降级操作**。
* 优点：提升了灵活性，不用担心类型错误；节约内存，在有需要的时候才进行升级。

## 压缩列表 ziplist
压缩列表是列表键和哈希键的底层实现之一。是一种节约内存的顺序型数据结构。

> 基本结构
包含压缩列表和压缩节点两种。

一个压缩列表可以包含任意多个节点，每个节点保存一个字节数组或者一个整数值。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201122201124679.png#pic_center)
* zlbytes：记录整个列表占用的内存字节数。
* zltail：记录表尾距离表的起始地址的偏移地址。可以$O(1)$复杂度得到表尾地址。
* zllen：记录了表的节点数量，小于65535才可，不然需要遍历。
* entry：列表的节点，节点的长度不一定。
* zlend：特殊值0xFF表示末尾。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201122201516240.png#pic_center)

* previous_entry_length：前一节点的长度。前一节点长度小于254字节，当前pel长1字节，否则5字节且第一字节是0xFE。可以根据当前的节点的起始位置得到前一节点的起始地址。从而从尾向头进行遍历。
* encoding：表示了编码方式。
* content：表示具体的内容。

> 结构特点
* 连锁更新问题
某个节点一旦需要重新分配地址，如长度变化等，就需要更新后续的全部previous_entry_length

# 对象
利用五种不同类型的对象，redis可以在执行命令之前根据对象的类型进行判断命令是否合法。另外一个好处是可以**针对不同的适用场景采用合适的数据结构进行实现**。

并且redis实现了**基于引用计数的内存回收机制**，某个对象不被引用就会被回收；并且可以实现**对象共享**，通过让多个数据库键共享一个对象来节约内存。(为什么这里不会出现循环引用呢？因为redis对象之间没有深层次的嵌套，不会出现循环引用)

## 对象的类型和编码
在redis中新建一个键值对，会创建一个*字符串值的键对象*和一个*值对象*。其中值对象可以是五种基本类型。并且会有一个指向底层实现数据结构的指针。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201122203058969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)

### 字符串对象
字符串对象的编码可以是int、raw或者embstr。

* 如果字符串对象保存的是整数值，并且可以用long来表示。那么会以整数值进行保存，编码类型为int。
* 如果是字符串值，大于39字节是SDS的类型，编码类型为raw；小于39为embstr编码。embstr编码可以降低内存分配次数。


* Q:假如Redis string类型的value普遍都在10M，会有什么问题？
  
  如果只是读取的话，没啥问题，现在的磁盘的IO基本上是500M/s，带宽基本上是千兆或者万兆的，10M大小的key，对于读取的场景，只要不把网卡打满，就没啥问题。如果是读取+写入的场景，就会导致集群抖动比较严重，并发和性能都上不去。redis的性能瓶颈在于IO读写，因此后续的版本发布了多线程。
### 列表对象
可以使用ziplist或者linkedlist。相当于LinkedList，插入和删除非常的快，但是索引定位很慢 O(n)。列表结构可以被作为异步队列使用。

ziplist编码中，每个节点都存了一个列表元素；linkedlist这个双段列表中，每个节点都保存了一个字符串对象，每个字符串对象保存了一个列表元素。

* ziplist编码：当列表对象中所有的字符串元素长度小于64字节并且元素数量小于512个。
* linkedlist编码：其余情况。

### 哈希对象
可以使用ziplist或者hashtable。字典的值只能是字符喜欢。

ziplist中，先把保存了键的压缩链表节点压在队尾，再把保存了值的压缩列表节点压入队尾。hashtable使用了字典。

* ziplist编码：所有键值对字符串长度小于64字节并且数量小于512。
* hashtable编码：其余的情况。

### 集合对象
可以是intset或者hashtable编码。当集合所有元素是整数且数量不超过512个时采用intset编码，否则是hashtable编码。

### 有序集合对象
可以是ziplist或者skiplist编码。当数量小于128且元素长度小于64字节使用ziplist。

对于skiplist编码，使用了zset作为底层结构，**一个zset结构同时包含了一个字典和一个跳跃表**。其中跳跃表按照分值从小到大保存了全部的元素，因此**可以对有序集合进行范围查找**等。此外zset还用字典等建立一个从成员到分值的映射，**可以在$O(1)$的复杂度下找到成员分数**。并且两种数据结构会通过**指针来共享相同元素的成员和分值**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/202011222054254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)

采用通过这种设计，可以$O(1)$的根据成员名字找到分数，并且跳跃表也实现了范围查找。

每个跳跃表的节点高度都是1-32的随机数，同一个表可以有多个节点分值一样，但是节点的成员对象必须唯一（因为叫集合呢），跳表按照分数从大到小排序，如果分数一样按照成员的大小排序。

在具体实现上是每个节点都是随机的，给定了一个概率，然后每次重复随机数，小于就+1。最后看看生成几层。

#### zset的使用场景
1. 记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。 记录热榜帖子 ID 列表，总热榜和分类热榜。记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。

2. 限流：滑动窗口是限流常见的一种策略。如果我们把一个用户的 ID 作为 key 来定义一个 zset ，member 或者 score 可以都为访问时的时间戳。我们只需统计某个 key 下在指定时间戳区间内的个数，就能得到这个用户滑动窗口内访问频次，与最大通过次数比较，来决定是否允许通过。


3. 延迟队列：zset 会按 score 进行排序，如果 score 代表想要执行时间的时间戳。在某个时间将它插入 zset 集合中，它变会按照时间戳大小进行排序，也就是对执行时间前后进行排序。



## 对象的特点
### 类型检查与命令多态
在执行一个特定的指令之前，会检查数据库键对应的值对象的类型是否可以合法。**某些是可以对于多个类型的多态，某些是基于编码实现的多态。**

### 内存回收
每个对象都有一个**引用计数**，在被初始化时候为1，每被一个新程序引用便加一，不在被引用就减一，引用为0时该对象占用的内存被释放。

### 对象共享
可以让数据库键的值指向一个现有的值对象（一般是0-9999的字符串对象），并将被共享的对象的引用计数加一。但是一般都是针对字符串键或者嵌套了字符串的键，因为比较容易在$O(1)$的复杂度内比较相等。

### LRU属性

**会记录对象最后一次被程序访问的时间，在内存满了之后lru大的那部分键会被优先释放。**

# Redis持久化
Redis时内存数据库，因此速度快，但是我们需要把数据存回硬盘，因此需要持久化。

## RDB持久化
RDB持久化功能所生成的RDB文件时一个**经过压缩的二进制文件**，通过该文件可以还原生成的RDB文件。

### RDB文件的创建与载入
两个指令可以生成RDB文件`SAVE`和`BGSAVE`。**SAVE会阻塞Redis服务器进程，直到EDB文件创建完毕。BGSAVE会派生出一个子进程，然后子进程负责创建RDB文件，父进程继续处理命令。** 原理上是**fork+cow**，首先fork出来一个子进程，然后通过操作系统的COW（copy on write）机制实现快照持久化。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。

Redis的载入是服务器启动时候自动执行的。需要注意的是，由于AOF的更新频率比RDB高，**因此如果服务器开启了AOF持久化，服务器会优先采用AOF来恢复。**

BGSAVE执行期间，客户端的SAVE和BGSAVE指令会被拒绝，BGREWRITEAOF会被延迟到BGSAVE执行完毕；如果BGREWRITEAOF正在执行，BGSAVE会被拒绝。

### 自动保存
一般BGSAVE会在一定条件下自动执行，如900s以内数据库执行了至少一次修改；300s内数据库执行了10次修改；60s内执行了10000次修改。这里依靠了两个全局变量，一个是**dirty计数器**，统计了上次保存之后，服务器进行了多少次修改，一个是**lastsave保存了上次的成功save的事件戳**。Redis的周期性函数severCon每100ms执行一次检查，如果满足条件就BGSAVE。

### RDB文件结构
redis五个字符，db_version四个字节保存了版本号，EOF是结尾标志，check_sum是检验和。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201123111254881.png#pic_center)


## AOF持久化
AOF（Append Only File）与RDB直接保存数据库中的键值对来记录数据库的状态不同，**AOF持久化是通过保存服务器所执行的写命令来记录数据库状态的**。被写入AOF文件的所有命令都是以Redis命令请求协议格式保存的。

### AOF持久化的实现
**在服务器执行完一个写命令以后，会在服务器状态的 aof_buf 缓冲区末尾追加一个写命令。并定期的同步到AOF文件中。**

Redis的服务器进程就是一个事件循环，有两种事件，一个是文件事件负责接收客户端的命令请求，以及发送回复到客户端。另外时间事件负责执行类似severCron函数这样需要定时运行的函数。

因此服务器每次结束一个事件循环之前，都会调用flushAppendOnlyFile的函数，考虑是否将 aof_buf 缓冲区的内容写入AOF文件中。其中分为三个时间参数：
1. `always`每次都将缓冲区的全部数据写入AOF文件中并同步；
2. `everysec`如果上次同步时间距离现在超过1s，则进行一次同步，这个过程是一个线程专门执行的；
3. `no`只是写入AOF但是不同步到硬盘。

AOF载入过程中，回有一个伪客户端执行AOF的命令，直到完成全部恢复工作。

### AOF重写
为了压缩AOF文件的大小，redis提供了AOF文件重写功能，可以创建一个新的AOF文件来替代现有的AOF文件，也就是`BGREWEITEAOF`。

事实上AOF的重写不需要对现有的AOF文件进行任何的读写，而是用个服务器状态实现。在**重写过程中会忽略过期的键**。重写名列最多包含64个键值对，否则还是要多个语句。

为了提高性能，redis将AOF的重写程序放在了子进程中执行，这样服务器进程可以正常相应客户端的请求，并且子进程有服务器进程的数据副本，可以保证数据安全。**同时为了解决不一致问题，redis服务器设置了一个AOF重写缓冲区，在子进程创建之后，redis的写命令会同时给AOF缓冲区和AOF重写缓冲区。在完成AOF的重写后，子进程给父进程发送一个信号，父进程阻塞并且将重写缓冲区的内容写入AOF文件中，并原子的覆盖原AOF文件，完成整个任务。**


## 4.0的混合持久化
将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

# redis事件
redis服务器是一个事件驱动模型，包括文件事件和时间事件。redis服务器通过套接字与客户端进行连接，而文件事件就是服务器对套接字操作的抽象。

### 文件事件
文件事件处理器被用于处理文件事件。虽然redis是单线程的，但是处理器采用**IO多路复用**，监听多个嵌套字，提高效率。事件处理器分为四个组成部分，套接字，IO多路复用，文件事件分派器，事件处理器。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201124104858805.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)
### 时间事件

服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。时间事件又分为：

    定时事件：是让一段程序在指定的时间之内执行一次；
    周期性事件：是让一段程序每隔指定时间就执行一次。

Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。


* Q:Redis的线程模型可以说下吗？

A ：首先redis是一个单线程模型。也是redis性能比较好的一个因素。虽然是单线程的模型。但是redis采用了**IO多路复用**，可以同时监听多个套接字，提高效率。这部分也就是redis事件处理器。当被监听的套接字准备好执行连接应答、读写等操作时，会产生相应的文件事件，并且会进入一个FIFO队列里面，依次被执行。然后文件事件分派器会将任务交给不同的事件处理器。

时间和文件时间都是原子的，服务器会轮流处理。使用的是`selector`类型的NIO。


# Redis多机数据库
> 复制
在redis中，用户可以通过`SLAVEOF`命令，让服务器区复制另外一个服务器。被复制的服务器为主服务器，执行复制的服务器是从服务器。
### 全量复制
从服务器向主服务器的同步操作需要向主服务器发送`SYNC`命令。收到SYNC命名的主服务执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令。**从服务器在写入RDB文件之后，主服务器在发送缓冲区的命令，实现同步。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201126095611513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)
* 命令传播

主服务器需要对从服务器执行命令传播，在执行完自己的写命令之后，发送给从服务器执行。

* 缺陷

对于断线以后的复制依然是完全重新复制，十分低效。只有在真正必要的时候才有执行`SYNC`操作。

## 增量复制
具有完整重同步和部分重同步功能。其中完成重同步功能`PSYNC`用于处理断线以后的复制情况。

### PSYNC
三个部分组成：主服务器的复制偏移量和从服务器的复制偏移量，主服务器的复制积压缓存区和服务器的运行ID。

* 复制偏移量：两个服务器都会维护，每次写入N字节数据，偏移量就+N。如果主从服务器是一致的，两个服务器的偏移量应该一样。
* 复制积压缓冲区：主服务维护的一个固定长度的，先入先出的队列，默认大小为1MB。主服务器进行命令传播时候，还会将写命令入队到复制积压缓冲区。当主服务器收到PSYNC时，如果offset偏移量之后的数据不在缓冲区，执行完成同步如果在偏移位置在缓冲区，执行部分重同步。缓冲区的大小一般设置为2*second*write_size_persecond。
* 运行ID：标识身份。只有之前相互连接过才可能部分复制。

### 复制的实现
设置主服务器的地址和端口-->建立套接字连接-->发送PING命令-->身份验证-->发送端口信息-->同步-->命令传播。复制过程中，两者互相为对方服务器。

## 心跳检测
在命令传播阶段，从服务器会默认每秒一次的频率向主服务器发送自己的复制偏移量。
`REPLCONF ACK <replication_offset>`。主要有以下作用：
* 检测网络连接：如果主服务器超过一秒没收到REPLCONF ACK指令，会意识到出现连接问题。
* 辅助实现min-slaves：redis可以指定最小从服务器数量和延迟，如在从服务器数量小于3个或者三个从服务器的延迟大于10s时，主服务器拒绝写命令。防止不安全的情况。
* 检测命令丢失：心跳检测时含有从服务器的偏移量的，主服务器会察觉从服务的缺少的数据，并且重新发送。（类似PSYNC）


# Redis Sentinel哨兵模式
哨兵模式时Redis**高可用性**的解决方案：由一个或多个Sentinel实例组成的哨兵系统可以键是任意多个主服务器及其下属从服务器。并在主服务器下线情况下，选择从服务器升级为主服务器。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020112610241399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)

### 启动并且初始化Sentinel
Sentinel本质是是一个特殊模式的Redis，但是在初始化Sentinel时候，不需要载入RDB和AOF文件。并且Sentinel具有专用的代码。

服务器会初始化一个sentinelState的结构，保存了服务器中与Sentinel有关的状态，如`current_epoch`。还有一个字典保存了全部被sentinel监控的主服务器，键是主服务器名，值是sentinelRedisInstance类型的指针。

sentinelRedisInstance是一个实例，可以是主从服务器，也可以是另外一个sentinel。该结构保存了各个实例结构的信息，如`config_epoch`，实例地址等。

> 创建连向主服务器的网络连接

Sentinel会创建两个连向主服务器的异步网络连接：
1. **命令连接**--专门向主服务器发送命令
2. **接受回复和订阅连接**--订阅`_sentinel_:hello`频道。

![在这里插入图片描述](https://img-blog.csdnimg.cn/202011261036069.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)

> 获取主从服务器信息
> 
Sentinel每隔10s，通过命令向被监视的主服务发送`INFO`命令。主服务器返回的信息包括了本身信息和从服务器的信息。Sentinel通过这个反馈来发现并更新从服务器的信息。Sentinel端会更新主服务器实例下slave字典的信息。

在发现新的salve之后，sentinel会与salve建立命令连接和订阅连接。同样每个10s进行INFO命令。并更新认识。

> 向服务器发送和接受订阅

Sentinel每隔2s，以命令连接的方式发送PUBLISH指令，要求每个服务器在**hello频道发布消息**，包括Sentinel的信息和服务器的信息。（ip，端口号，运行ID，配置纪元）。

同样Sentinel会接收到别的Sentinel发送的消息，这个消息会**更新对Sentinel的认识**。因此会更新主服务器字典中，监视该服务器的sentinel信息。也就是说，**监视同一个主服务器的多个Sentinel可以自动发现对方**。并且，**两个Sentinel之间也会建立命令连接**。

## 故障检测与处理
> 检测主观下线


默认情况下，Sentinel会以每秒一次的频率向所有与它建立了命令连接的实例发送`PING`指令。如果在`down_after_milliseconds`内没有收到有效回复，会被标记为主观下线，打开`SRI_S_DOWN`标识。多个Sentinel设置的主观下线时长可能不同的。

> 检测客观下线


在确认了主观下线之后，Sentinel会询问其他连接这个服务的Sentinel，如果接受了足够多的判断，则判定为客观下线，准备进行故障转移。多个Sentinel设置的客观下线投票数可能不同的。

> 选举领头Sentinel
> 
当主服务器被判断为客观下线时，监视这个服务器的Sentinel会协议选举一个**领头Sentinel**，处理故障转移。
1. 每个监视这个下线服务器的Sentinel都可以被选择
2. 每次进行完选举，无论是否成功，所有Sentinel的config_epoch都加一。
3. 每个配置纪元，所有Sentinel都只能选择一次且无法更改。
4. 当源Sentinel发送`SENTINEL is-master-down-by-addr <IP> <port><current_epoch><runid>`给目标Sentinel，会按照先到先得设置为局部领头。如果成功设置，回复中附有`<leader_runid><leader_epoch>`
5. 源Sentinel在检查epoch一致的前提下，计算票数，过半胜利。
6. 如果选举失败会在一定时间之后重试。

算法的本职是RAFT算法。

> 故障转移
1. 在下线服务器的slave中选择一个变为master。
2. 让其他slave变为新的master的salve。
3. 让下线服务器变为当前master的salve。

master挑选依据，正常在线；删除5s内没有回复过领头SentinelINFO命令的；删除断开时间超过“主观下线时间”*10毫秒的，然后按照优先级排序，再选择offset最大，如果还一样，选择ID最小的。

在领头Sentinel发送了SLAVEOF no one之后，会以每秒一次的频率发送INFO给升级服务器，观察角色变化。



# Redis集群
Redis集群是Redis提供**高可拓展性**的**分布式数据库方案**，集群通过水平分片来进行数据共享，并提供复制和故障转移功能。

## 节点
一个redis集群由多个节点组成，多个节点聚集称为一个集群。`CLUSTER MEET <ip> <port>`将一个节点添加进入另外一个节点。A节点在联系上了B节点以后会通过Gossip协议传播这一信息给集群中其他节点。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201126163123786.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)


节点会继续使用redisSever结构保存服务器状态，redisClient保存客户端状态。对于集群的状态分布在clusterNode，clusterLink以及clusterState结构中。

* clusterState：记录了当前节点的视角下，集群目前的状态，包括集群节点个术和集群的配置纪元(current_epoch)。其中由集群的节点名单，键为节点的名字，值为节点对应的clusterNode结构。
* clusterNode： 保存了一个节点当前的状态，如创建时间，配置纪元(config_epoch)等。每个节点都会用clusterNode记录自己的状态，并为集群中其他节点创建一个对应的clusterNode结构。
* clusterLink：保存了连接节点需要的信息，如套接字描述，输入缓冲和输出缓冲。

## 槽指派
集群通过**分片的方式保存数据库中的键值对**，整个数据库被分为16384个槽。每个节点可以处理0个或者最多16384个槽。当全部的16384个都有节点在处理时，集群上线；如果有任何一个槽没有被处理，集群都处于下线状态。


槽指派信息是记录在clusterNode中的，其中slots是一个二进制数组，由**2048个字节，也就是16384个二进制位**。可以按照索引填写1，0区分当前节点是否处理该槽对应的数据。并且每个节点还会传播自己的槽指派情况，告知集群中其他节点自己目前处理哪些内容。其他节点将相应的信息保存到对应节点的clusterNode结构中。

另外还clusterState结构中的slots数组记录了集群中16384个槽的指派信息，每个数组项都是一个clusterNode类型的指针，指向被分配的节点。这种双重的保存，降低了复杂度。**clusterState.slots数组记录了集群中所有槽的指派信息，clusterNode.slots录了当前节点的槽指派情况**。

## 命令执行
接受命令的节点会计算命令要处理的数据库键在那个槽位，如果是自己的任务就处理，否则返回一个Moved报错，并且引导客户端转向正确的节点。

* 计算键属于那个槽位：`CRC16(key) & 16383`得到槽位。
* 判断节点：clusterState.slots查表O(1)复杂度。如果不是当前节点，给客户端返回错误`MOVED <slot> <IP>:<PORT>`引导进行跳转。
* 节点数据库的实现：节点除了将键值对保存在数据库中，还在clusterState中的slots_to_keys跳表结构保存的了槽和键的关系。每个节点的分值是槽号。因此可以进行批量操作。

## 重新分片
修改键值对在槽中的存储。重新分片可以在线处理，不要下线。重新分片需要通过集群管理软件redis-trib。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201126163228348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70#pic_center)
1. rt给目标节点发送setslot指令，通知目标节点准备好从源节点导入。
2. rt给源节点发送setslot，通知准备。
3. 执行图1。并且反复执行2.3直到全部完成复制。
4. rt向任意节点发送`cluster setslot <slot> Node <target_id>`，告诉整个槽位的变更。

## ASK错误
如果源节点没能在自己的数据库中找到指定的键，可能这个键发生了转移，源节点将发送一个ASK错误，指引客户端转向到目标节点。(本应在自己这里但是不在)

实际上在clusterState 的中由数组分别维护当前正在从其他节点导入的槽，和当前节点正在迁移到其他节点的槽。

如果节点没有在自己的数据库中找到key，就回去检查自己的迁移数组，看看是不是在迁移。并且返回ask，指引客户端。ask命令会打开发送命令的客户端的redis_asking标识，这个标识是一次性的，使用之后就会被移除。当客户端收到ask错误进行跳转时候，会先给节点发送asking指令，然后才重新发送想要执行的指令。不然会被拒绝并发送Move指令。

* ASK错误与MOVED错误

MOVED错误代表槽的控制权已经从一个节点转移到另外一个节点。而ASK节点是一个临时性策略。


## 复制与故障转移
redis集群中的节点同样分为主节点和从节点。其中主节点处理槽，而从节点则用于复制主节点。

### 故障检测
集群中每个节点会定期向集群中其他节点发送PING，如果某个节点没有在规定时间内回复PONG。会被标记位疑似下线PFAIL。此时，集群中的节点会相互确认，如果在一**个集群中**，半数以上处理槽的**主节点**，都将某个主节点标注位疑似下线，这个主节点将会变为已下线FAIL，并向集群广播一条关于主节点的FAIL消息。

### 故障转移
当一个从节点发现自己的主节点出现了已下钱的标识，会开始进行故障转移：
1. 该主节点的所有从节点中会由一个从节点被选为主机点，执行SLAVEOF no one.
2. 新的主节点会撤销所有下线节点的槽指派，改为指派自己。
3. 向集群广播PONG消息，让集群其他节点只道从节点上位了，并且接管了槽。

### 选举主节点的方法
1. 集群的某个节点开始故障转移时，集群配置纪元`curruntepoch`都+1。
2. 每个纪元中，每个主节点都只有一次投票机会。先到先得。
3. 当从节点发现自己父节点先下线，向集群广播一下`CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST`消息，要求收到的主节点投票。
4. 可以进行投票的主节点会回复消息。
5. 故障处理由延迟时间：<font color='red'> 500ms+random（0-500）+rank*1000ms</font>。固定延迟保证达成共识已经下线，random保证去同步性，rank是从节点之间通信，得到最新的offset的节点rank最低。
6. 只要的票大于所有主节点的一半，称为成功。

## 消息
集群中由五种 消息：
* <font color='red'> MEET</font>：请求接受者加入到发送者当前的集群当中。
* <font color='red'> PING</font>：集群中的每个节点默认每个一秒钟就会从已知节点列表中随机选择五个节点，然后对这5哥节点中最长时间没发送过PING的节点发送PING。此外，如果节点A最后一次收到节点B的PONG消息时长超过了cluster-node-timeout的一半，会再次发送PING消息。防止更新滞后。
* <font color='red'> PONG</font>：收到MEET和PING消息后进行回复。此外也可以利用集群广播发送自己的PONG消息，让集群其他节点立刻刷新对自己的认知。如完成某一次故障转移之后。
* <font color='red'> FAIL</font>：当主节点A判断另外一个主节点B已经下线时，节点A会向集群广播一条B的FAIL消息，收到消息的节点都会立刻将B标记为已下线。
* <font color='red'> PUBLISH</font>：当节点收到PUBLISH命令时，节点会执行这个任务，并且集群广播一条PUBLISH命令，所有接收到这个消息的节点都会执行相同的命令。

前三种消息都是采用的Gossip协议来实现的节点之间的状态信息的交换。节点通过消息头判断消息的具体类型。

FAIL消息因为需要立即让集群所有节点知晓，因此单纯采用Gossip协议传播会存在一定的延迟，因此采用集群广播。


# 缓存击穿、缓存穿透与缓存雪崩
>正常流程

前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20201208173602355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)

## 缓存穿透
缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果**从存储层查不到数据则不写入缓存**，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

**解决策略**：
**布隆过滤器**：接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

缓存空对象：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。

## 缓存击穿
缓存击穿是指**缓存中没有但数据库中有的数据（一般是缓存时间到期）**，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

与下面缓存雪崩的区别在于，这里是某一条数据过期造成的。

 **解决方案：**
1. **设置热点数据永远不过期**，但是会增加空间消耗。
2. 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。
 3. **布隆过滤器**。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小，
3. **加互斥锁**，互斥锁。保证只有一个线程可以查询热点的key。[参考代码](https://blog.csdn.net/fcvtb/article/details/89478554)

## 缓存雪崩
缓存雪崩是指**缓存中数据大批量到过期时间，而查询数据量巨**大，引起数据库压力过大甚至宕机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

**解决方案：**
1. **缓存数据的过期时间设置随机**，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
2. 设置热点数据永远不过期。


## 布隆过滤器
一句话概括，很多个hash函数在一起。 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

由**位数组**和**一系列哈希函数**两部分组成的数据结构。它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。

当一个元素加入布隆过滤器中的时候，会进行如下操作：

  >使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
  根据得到的哈希值，在位数组中把对应下标的值置为 1。

当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：

  >对给定元素再次进行相同的哈希计算；
  得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。
# 缓存更新策略(Redis和Mysql的一致性)
[参考资料](https://www.cnblogs.com/yanglang/p/9098661.html)
## 存在问题的几种缓存更新问题
1. 如果先更新数据库再更新缓存：会产生脏写问题。
![](https://img-blog.csdnimg.cn/img_convert/0e24b8992ebab233d782b76df5e56104.png)
首先不可以采用先更新缓存再更新数据库，会发生异步的脏读。
2. 先删除缓存，再更新数据库：
 - 请求A进行写操作，删除缓存 
 - 请求B查询发现缓存不存在 
 - 请求B去数据库查询得到旧值 
 - 请求B将旧值写入缓存 
 - 请求A将新值写入数据库 上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 

解决的思路：延时双删策略，（1）先淘汰缓存 （2）再写数据库（这两步和原来一样）（3）休眠1秒，再次淘汰缓存这么做，可以将1秒内所造成的缓存脏数据，再次删除。 

3. 先更新数据库，再删除缓存（FaceBook）
  **写先写db**，然后在redis中更新；**读先读redis**，没有去db中更新到redis中。
    * 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
    * 命中：应用程序从cache中取数据，取到后返回。
    * 更新：先把数据存到数据库中，成功后，再让缓存失效。
这种策略的核心在于认为数据库的读操作的速度远快于写操作的

 **异步缓存写入：只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。比如采用消息队列的方法。**
# redis事务
通过MULTI、EXEC、WATCH等命令实现事务功能。在事务执行完毕旗舰，服务器不会中断事务而去执行其他客户端的命令请求。

每个redis客户端都有自己的事务状态，这个事务状态保存在客户端状态（redisClient）中。事务状态包含一个事务状态和一个已入队命令计数器。事务队列采用先进先出的方式保存入队命令。在客户端向服务器发送EXEC命令之后，服务器会遍历这个事务ui列，执行命令。

## WATCH命令（乐观锁）
实际上WATCH命令是一个**乐观锁**，在执行EXEC命令之前，监视任意数量的数据库键，并且在EXEC执行时，检查被监视的键是否存在被修改，如果是的话，服务器会拒绝执行事务，并返回事务失败。

* 实现方式：
 数据库（redisDB）保存了一个watched_keys的字典，键是被watch的数据库键，字典的值是一个链表，链表记录了所有监视这个键的客户端。执行数据库修改指令时，会检查字典，看看有没有被监视的键，如果有被监视的键刚刚被修改，就会打开客户端的REDIS_DIRTY_CAS标识，表示事务的安全性被破坏。

在执行EXEC之前，服务器会检查客户端的CAS标识有没有被打开，如果是则拒绝执行事务。

## ACID性质
* 原子性
Redis是原子性的，事务队列的命令要不全部执行，要不一个都不执行。如果事务出现了命令入队错误，事务中的所有命令都不会被执行。但是，与其他关系型数据库不同，redis不支持事务回滚机制。即事务队列中某个命令在执行期间出现了错误，整个事务也会继续执行。

Redis的作者解释说，不支持事务回滚是因为这种复杂的功能和redis追求的简单高效的设计主旨不符合,并且他认为，redis事务的执行时错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中,而很少会在实际的生产环境中出现，所以他认为没有必要为redis开发事务回滚功能。
* 一致性
数据符合数据库本身的定义和要求，没有包含非法和无效的错误数据。（redis是满足的一致性的？这点我存疑，按道理只有满足原子性才能继续讨论一致性。当然，这个给出的一致性似乎和mysql的一致性标准不太一样。）
* 隔离性
Redis是单线程的方式执行事务，因此串行运行，是隔离的。
* 持久性
这取决于持久化的参数。主要是AOF的参数。太高的持久化频率会影响性能。
# Redis的使用场景
## 分布式锁
目前分布式锁最主要有三种实现方式：[blog解析](https://blog.csdn.net/zcz5566719/article/details/120295503)

1. 基于 Redis 集群的模式；
2. 基于 Zookeeper 集群的模式；
3. 基于 DB 数据库的模式

分布式锁本质上要实现的目标就是在 Redis 里面占一个位置，当别的进程也要来占时，发现已经有人占用在那里了，就只好放弃或者稍后再试。占坑一般是使用 `setnx`(set if not exists) 指令，只允许被一个客户端占坑。先来先占，用完了，再调用 `del` 指令释放。我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也可以保证 5 秒之后锁会自动释放。
``` redis
> setnx lock:codehole true
OK
> expire lock:codehole 5
> del lock:codehole
```

但是这两个指令不是原子的，依然可能导致问题。因此我们需要合成为一个指令。
```
set lock:codehole true ex 5 nx
```

### 可重入性
Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。

### 锁冲突
1. 直接抛出异常，通知用户稍后再试。本质上是放弃请求。
2. sleep一会重试。
3. 将请求转移到延时队列，一会再试。

## 异步消息队列
Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用lpop 和 rpop来出队列。
但是redis不是专业的消息队列，无法保证百分百的可靠性。且不支持多播。（消息多播允许生产者生产一次消息，中间件负责将消息复制到多个消息队列，每个消息队列由相应的消费组进行消费。）

### 消费队列
使用 blpop/brpop 命令可以让队列空了以后阻塞。如果线程一直阻塞在哪里，Redis 的客户端连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候blpop/brpop会抛出异常来。所以编写客户端消费者的时候要小心，注意捕获异常，还要重试。
### 延时队列
延时队列可以通过 Redis 的 **zset**(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的**value**，这个消息的**到期处理时间作为score**，然后用再java段采用多线程**轮询 zset 获取到期的任务进行处理**，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。

### 如何唤醒一个延迟任务

考虑一个环状链表，假设最短时间分辨是m，环状链表的长度为n。如果我们有一个任务需要延迟k，那么我们就需要在 `(k/m)%n`的位置，插入这个任务就可以了。具体的可以在这个链表node节点数据结构中存储一个list维护所有的任务。然后到了这个节点的位置时候就进行异步提交。


## 缓存
这里包括了对象缓存，全页缓存，热点数据的缓存等。

并且redis是分布式的独立缓存，可以多个应用之间共享缓存。

## 全局id，计数器，限流
全局id：int类型，incrby，利用原子性，和单线程的特点。对于分库分表的场景可以一次拿一段id。

计数器：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库

限流：以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false

## 位统计
可以统计在线用户等，计算过去七天的在线用户。

## 点赞签到打卡
使用set结构，假如上面的微博ID是t1001，用户ID是u3001

用 like:t1001 来维护 t1001 这条微博的所有点赞用户

  - 点赞了这条微博：sadd like:t1001 u3001
  - 取消点赞：srem like:t1001 u3001
  - 是否点赞：sismember like:t1001 u3001
  - 点赞的所有用户：smembers like:t1001
  - 点赞数：scard like:t1001

类似的结构也可以用于存储标签之类的

## 点赞排行
zset数据结构
- id 为6001 的新闻点击数加1：zincrby hotNews:20190926 1 n6001

- 获取今天点击最多的15条：zrevrange hotNews:20190926 0 15 withscores

# 其他问题


## 为什么要用Redis

随着时代的发展，数据量逐渐加大。最开始是单机MySql时代，但是这种方式需要不断的查找数据库，效率低。因此考虑采用了缓存的方法。memecache。
后面开始考虑表的垂直切分，多数据库协同。到最后的集群。


> NoSQL特点
NoSQL = NotOnly SQL。可以不需要传统MySQL的表行列。非关系数据库。
解耦！
1. 方便扩展（数据库之间没有关系，很好扩展！）
2. 大数据的高性能，基于缓存，读写速度很快
3. 数据类型多样，不需要事先设计数据库。

Redis（remote dictionary sever）远程字典服务。基于内存，可以持久化的日志型、Key-Value数据库。


## 发布与订阅
通过SUBSCRIBE命令，客户端可以订阅一个或者多个频道。或者通过PSUBSCRIBE订阅一个或者多个模式。

Redis中频道是采用了字典的形式，键的值是一个链表。每有新增加的订阅者，就把客户端添加到订阅者链表的尾部。而模式订阅采用了链表的结构，链表中的每个节点都包含了一个Pubsub Pattern结构。保存了客户端的名称和订阅的模式



[mysql操作](https://blog.csdn.net/zcz5566719/article/details/108562099)

# Redis数据库
Redis服务器将所有数据库都**保存在redisSever结构的db数组**中，db数组的每一项都是一个**redisDb**结构，代表了一个数据库。一般默认初始化16个数据库。可以通过`SELECT`指令切换数据库。

Redis是一个键值对数据库服务器，redisDb结构的**dict字典**保存了数据库中的所有键值对，将这个字典成为键空间。键空间的键是数据库的键，每个键都是字符串对象。值可以是任意一种Redis对象。并且还有一个**expires字典**保存键过期信息。

## 读写键空间时的维护操作
* miss与hit
在读取一个键之后（包括读操作和写操作），服务器会根据键是否存在，更新服务器中命中率（hit）和不命中（miss）的次数。

* LRU更新
在读取一个键之后，服务器会更新LRU，用于计算闲置时间。
* 删除过期键
在读取时候发现某个键已经过期，会先删除这个过期键，再执行其他操作。
* 标记dirty
如果由客户端使用`WATCH`指令监视了某个键，那么服务器在对被监视的键进行修改的之后，会把这个键标记为dirty，从而让事务处理器注意。
* dirty计数器增加
服务器每次修改一个键之后，都会对dirty计数器增1.这个计数器会触发服务器的持久化和复制操作。
* 发送数据库通知
如果开启了数据库通知，在对键进行修改之后，服务器会按照配置发送数据库通知。

## 键的生存过期时间
通过`EXPIRE`或者`PEXPIRE`可以对某个键只是生存时间，在过了生存时间之后，服务器会删除生存时间为0的键。`EXPIRE<key><ttl>`设置生存时间为ttl秒，`EXPIREAT<key><timestamp>`某个键的过期时间设置为timestamp指定的秒。

redisDb结构中expires字典保存了数据库中所有键的过期时间，称为**过期字典**。过期字典的键是一个指针，指向键空间的某个键对象，值是一个long long类型的整数，保存了过期时间（*键空间的键和过期字典的键都指向同一个键对象，节省空间*）。

`PERSIST`可以移除一个键的过期时间，`TTL`可以以秒为单位返回键的剩余空间。

## 缓存过期策略
* 过期键的判定

首先检查键**是否存在与过期字典**，如果存在返回过期时间；检查当前UNIX时间**是否大于过期时间**。

* 过期键删除策略
1. 定时删除：创建一个定时器，在过期时间来临时候删除。**内存友好，CPU不友好**，因为时间事件是无序队列，$O(N)$复杂度。
2. 惰性删除：放任过期时间不管，在再次访问改键时候进行判定。**CPU友好，内存不友好**。如果不去访问，相当于是一种内存泄漏。
3. 定期删除：每隔一段时间对数据库进行检查，删除过期键。折衷的方法。

* Redis中的**惰性与定期删除**

惰性：所有的命令**执行前都会调用expireIfNeed，检查过期情况**。因此每个命令的实现函数都需要能执行键存在和不存在两种情况。

定期：由activeExpireCycle执行，redis服务器的周期性程序severCron被执行时，该方法被调用。在规定的时间内，分多次遍历服务器的各个数据库。每次运行时，从一定数量的数据库中**选择一定数量的随机键检查并删除过期键**，并保存每次的进度，下次再被调用时候继续运行。

## AOF，RDB和复制对过期键的处理
* RDB对过期键的处理

在生成RDB文件时候，会检查过期情况，因此**RDB文件不会包含过期键**。载入过程中，**如果是主服务器，会对过期进行检查，过期数据不会被载入从服务器则全部加载。但是也不会有影响，因为从服务器会被主服务器同步。**

* AOF对过期键的处理

AOF生成过程中，**如果键已经过期但是没有被显式删除则不会对AOF有影响**，在被惰性或者定期删除之后，程序会在AOF文件之后跟一个DEL命令。**AOF重写中程序会检查过期情况，因此不会被存入AOF。**

* 复制操作对过期键的处理

主服务器在删除一个键之后，会显式的向从服务器发送del指令；**从服务在读取到过期键之后，不会进行任何操作而是正常返回，只是为了保持一致。**

## Redis的LRU （内存淘汰机制）
### Redis LRU策略分类


1. noeviction: 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。
2. volatile-lru: 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。
3. volatile-ttl: 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl越小越优先被淘汰。
4. volatile-random: 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。
5. allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。
6. allkeys-random: 跟上面一样，不过淘汰的策略是随机的 key。
7. volatile-lfu: Evict using approximated LFU among the keys with an expire set.(后面介绍)
8. allkeys-lfu: Evict any key using approximated LFU.(后面介绍)


volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。

### 近似LRU优化
所以不使用 LRU算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。

Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。

**Redis近似LRU算法惰性删除**
它的处理方式只有懒惰处理。当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次LRU 淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于maxmemory 为止。

如何采样就是看 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中随机，如果是 volatile 就从带过期时间的 key 字典中随机。每次采样多少个 key 看的是maxmemory_samples 的配置，默认为 5。

## 设计微信点赞
Redis数据库设计 redis是一个K-V数据库，没有统一的数据结构，针对不同的功能点，设计不同的数据结构类型

- 用户某篇文章的点赞数 使用HashMap<String, Set<String>>数据结构，HashMap中的key为articleId，value为Set，Set中的值为userId；
- 用户总的点赞数，使用HashMap<String, String>数据结构，key为userId，value为记录总的点赞数；
- 用户点赞的文章，使用HashMap<String, String>数据结构，key为userId，value为Set，Set中的值为articleId;