表有多大: 
一小时有 5000万条beacon，每条大概几十K，一小时2，3个T
一天 20T。

我在的团队是hulu广告智能团队下的data team，我们主要做的内容是负责hulu和disney的广告系统的数据仓库的搭建。21年底我们团队开始做一个比较大的项目就是给disney+平台上一套广告系统，之前disney是没有广告系统的。

我们组具体是负责把收集到的广告埋点数据，进行离线处理，包括对收到的事实数据做一些校验，归一化，以及和广告meta信息做聚合。这样我们可以根据用户观看行为的广告事实信息，得到关于广告播放收益，广告填充量和广告竞价竞价相关的更丰富的维度信息。

我是22年初加入的团队，正好那时候团队正在澄清项目需求和做流程设计。包括和上下游确定模型字段，表结构。以及我们内部需要确定对于数据处理的 具体 操作包括什么，比如字段归一化，对一些内容进行校验等。在这阶段我参与做了一些关于数据处理方案的设计工作。

对于数仓ELT的开发方面，我们组主要做的是离线处理业务，所以大数据处理框架选择是spark框架，底层的存储部署之类的技术是在AWS上搭建，比如数据存储实际上使用的是aws的s3存储，任务调度使用开源框架airflow去调度，数据监控用的grafana等。这部分我的工作就主要是实现之前的数据清洗，数据聚合，和异常流量过滤的代码。以及使用airflow框架搭建pipeline去调度任务，配合qa测试以及对spark job的性能进行调优。包括对pipeline配置一些警报之类的。

对于spark的性能调优主要是关注job是不是可以正常运行，以及运行的时间是不是过长，资源分配是不是合理的。

这部分工作中，做spark性能调优是比较有挑战的问题，我们有一个job是负责处理流量过滤的，我们对于流量过滤的规则有小时级别的，有天级别的，还有一个最长的是取过去13天的数据进行聚合过滤。13天的数据大概会有几百T，因此executor就会出现有些task持续OOM失败，导致job无法被正常的执行。解决这类spark性能优化问题就是看具体的spark执行失败的原因，我们当时发现的情况是有某一个stage执行的shuffle特别大，执行时间比其他的要长接近1000倍。定位到代码上的原因是我们在做一个过滤的时候，对于IP有ipv4和ipv6两个黑名单，只有有一个被命中了就会被过滤。因此我们比较自然的做了一个orJoinCondition的操作。这个操作其实不太好，这种or的join条件会导致笛卡尔积的产生（指定不等值连接，不指定on）。因此导致大量的读写。
```sql
-- https://zhuanlan.zhihu.com/p/536880775
select * 
from [TABLE A] t1 
join [TABLE B] t2 
on t1.id = t2.id 
or t1.name = t2.name;
```
而且导致这个问题更加恶化的是，我们对于这个join table mrc_blocked_ip，我们有一个去重的操作，dropDuplicate。这个操作会把小表切成200个分区去执行，进一步导致了笛卡尔积的增加。变成了200*200 = 40000个task去执行。

解决的方法，首先修复一下or的逻辑，做一下判断，有ipv4和ipv6的分别判断。然后对于shuffle问题，我们直接直接broadcast出去或者repartition（1）不让这个表去做分区。或者其实也是可以解决的。

还有一些可能发现有重复计算的rdd存在，这些rdd就可以cache或者persist一下，保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。

除了代码层面，还进行一些资源调优。包括增加executor-memory32G和executor number 64。类似的。


另外一个方面的工作就是，项目后期，有关于用户隐私法案的一些问题。美国那边的对数据隐私安全问题提出了一些chalange。这部分的工作是我和PM直接对接做design的。主要的需求是对于一些PII数据，我们不可以明文存储，并且需要应对RTD，用户有权要求删除。以及对于13岁以下的用户数据的PII不可以存储。其他用户的数据有一个最大存储期限，需要定期删除。

这部分工作也是需要结合一些广告业务的需求，因为我们其实会使用到一些用户的个人数据对用户的行为进行分析。比如用户画像之类的。用户的信息包括device-ad-id，ip address，accout-id这些。 对于我们来说有些数据是可以直接hash，我们也能使用的，比如ip，device id，因为我们主要是用于和黑名单上的ip和device进行比对进而进行流量过滤。但是ip信息对于有些下游团队是需要的，比如attribute团队做广告归因的时候就需要ip明文。



方案：
1. 对部分内容进行hash，比如device，ip等
2. 有一个compliance manager，可以按照用户的accout_id生成密钥，我们在进行数据处理时候，对于所有用户都请求密钥，然后对，ip等可能还需要解密的信息
等信息进行加密。
1. 对于可能的RTD情况，我们不在我们的数据里进行删除，而是删除compliance manager的数据。这样可以保证我们这里的数据在计算账单等信息的时候不出现不一致问题。
2. 对于U13内容，我们做了一个pipeline对这些字段进行删除，并且搬运到对外可见的db中。
3. 对于超过180天的数据定期物理删除


其他：

% action：Spark 调优（传统调优，数据偏斜，配置对不对），跟团队解决云上spark低效问题 (s3) 
    % 数据质量 （DQ），进行异步检查，发出对应的报警。DQ指标：是不是空，是不是变化的不正常，是不是一些信息的统计不正常，一个数据表有几十个。 异步的不会阻塞数据，如果出现问题，再重跑。 对于数据管理，正在做。

    ```
"account_id", "identity_id", "device_id", "device_ad_id_encrypted",
                            "ip_v4_encrypted", "ip_v4_hashed", "ip_v6_encrypted", "ip_v6_hashed"
```
