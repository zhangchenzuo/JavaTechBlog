- [OSI与TCP/IP的结构与功能](#osi与tcpip的结构与功能)
  - [应用层(HTTP, SMTP, DNS)](#应用层http-smtp-dns)
  - [传输层(TCP, UDP)](#传输层tcp-udp)
  - [网络层(IP, ARP)](#网络层ip-arp)
  - [数据链路层](#数据链路层)
  - [物理层](#物理层)
- [应用层（HTTP，DNS，STMP）](#应用层httpdnsstmp)
  - [Http协议](#http协议)
    - [URL和URI的区别](#url和uri的区别)
    - [Http的格式](#http的格式)
    - [请求方法](#请求方法)
      - [get和post的对比](#get和post的对比)
    - [http状态码](#http状态码)
    - [HTTP 和 HTTPS 的区别？](#http-和-https-的区别)
      - [http的安全问题](#http的安全问题)
      - [https](#https)
      - [数据签名与数字证书](#数据签名与数字证书)
    - [http1.0 1.1 2.0 区别](#http10-11-20-区别)
    - [HTTP的长短连接](#http的长短连接)
      - [长短连接的使用场景](#长短连接的使用场景)
  - [http缓存](#http缓存)
    - [Cookie的作用是什么?和Session有什么区别？](#cookie的作用是什么和session有什么区别)
      - [浏览器禁用cookie怎么办](#浏览器禁用cookie怎么办)
  - [http的服务器](#http的服务器)
  - [负责域名解析的DNS](#负责域名解析的dns)
    - [DNS解析过程](#dns解析过程)
    - [DNS优化](#dns优化)
- [传输层（TCP，UDP）](#传输层tcpudp)
  - [TCP协议确保可靠](#tcp协议确保可靠)
  - [TCP的三次握手与四次挥手](#tcp的三次握手与四次挥手)
    - [三次握手的流程](#三次握手的流程)
    - [三次握手的原因](#三次握手的原因)
      - [什么是SYN攻击](#什么是syn攻击)
  - [四次挥手](#四次挥手)
    - [最后为何等待2MSL](#最后为何等待2msl)
  - [TCP如何保证可靠传输](#tcp如何保证可靠传输)
    - [停止等待和连续ARQ协议](#停止等待和连续arq协议)
    - [滑动窗口和流量控制](#滑动窗口和流量控制)
    - [拥塞控制](#拥塞控制)
  - [TCP的状态机](#tcp的状态机)
  - [UDP](#udp)
    - [TCP和UDP的比较](#tcp和udp的比较)
    - [UDP想要实现可靠性传输怎么办](#udp想要实现可靠性传输怎么办)
  - [什么TCP的粘包](#什么tcp的粘包)
    - [造成TCP粘包的原因](#造成tcp粘包的原因)
    - [什么时候需要处理粘包现象？](#什么时候需要处理粘包现象)
    - [如何处理粘包现象？](#如何处理粘包现象)
  - [UDP会不会产生粘包问题呢？](#udp会不会产生粘包问题呢)
  - [TCP/UDP首部](#tcpudp首部)
- [网络层（IP协议，ARP协议）](#网络层ip协议arp协议)
  - [IP协议提供传输](#ip协议提供传输)
  - [网络层的ARP协议（ip->mac）](#网络层的arp协议ip-mac)
  - [Ping命令的过程](#ping命令的过程)
- [在浏览器输入url会什么过程。](#在浏览器输入url会什么过程)
  - [跨域请求](#跨域请求)

> 计算机网络
# OSI与TCP/IP的结构与功能
![](https://camo.githubusercontent.com/a24a29536633ebdf6e9326554d357c2b8acfae62026222573eb6cefd653bc5a3/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392f372f2545342542412539342545352542312538322545342542442539332545372542332542422545372542422539332545362539452538342e706e67)

## 应用层(HTTP, SMTP, DNS)
应用层协议定义的是**应用进程（进程：主机中正在运行的程序）间的通信和交互的规则**。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统**DNS**，支持万维网应用的 **HTTP**协议，支持电子邮件的**SMTP**协议等等。我们把应用层交互的数据单元称为**报文**。

## 传输层(TCP, UDP)
运输层(transport layer)的主要任务就是负责向**两台主机进程之间的通信提供通用的数据传输服务**。

**传输层把从应用层收到的数据进行分割，然后在报文上打上标记序号和端口号以后发送给网络层。**

传输层主要使用以下两种协议:

- 传输控制协议 TCP--提供面向连接的，可靠的数据传输服务。
- 用户数据协议 UDP--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。

**网络层为主机提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信**。
## 网络层(IP, ARP)
网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。网络层增加通信目的的MAC地址转发给链路层。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 IP 数据报 ，简称 数据报。

**路由器在这一层**

## 数据链路层
在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

**交换机在这一层**
## 物理层
在物理层上所传送的数据单位是比特。


# 应用层（HTTP，DNS，STMP）

## Http协议
### URL和URI的区别
URI是统一资源标识符，URL是资源定位符。URL的结构 协议+域名+端口

绝对URI：`http://user:pass@www.example.cn:80/dir/index.htm?uid=1#ch1`

URL:`http://www.exampe.cn`

### Http的格式
包括：请求行，请求头，请求数据

HTTP请求：方法+URI+协议版本（请求行） + 各种首段字段 + 实体主体（可选）
`POST /html/index.hetml HTTP/1.1`。

HTTP相应：协议版本+状态码+原因描述（状态行） + 响应头 + 主体

### 请求方法
  * get：请求相应的资源
  * post：用来传输实体的主体
  * put：传输文件
  * HEAD：和get类似，但是只需要返回请求首部。
  * Delete：删除文件。

  1.1以后增加了以下
  * Options：询问支持的方法
  * trace：追踪路径。返回之前请求的通信回环。
  * Connect：要求用隧道协议链接。

Http在1.1以后可以长连接或者管线化，长连接是不用每次http请求都要建立tcp，而是在一个tcp中多次请求http；管线化是可以在tcp链接以后，一次性发很多个请求，然后服务器慢慢响应。

#### get和post的对比
GET 用于获取资源，而 POST 用于传输实体主体。GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。

get是幂等的，多次调用客户端的结果一样，post不是幂等，多次调用会新增多个数据。

GET请求会被 浏览器主动cache，而POST 不会，除非手动设置。  GET产生 一个TCP 数据包；POST产生 两个TCP数据包
### http状态码
![在这里插入图片描述](https://img-blog.csdnimg.cn/978a631c781443368707aa167846164b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)



- 长连接：长连接适用于**操作频繁/点对点通讯**等**连接数不太多**的情况，如：一些游戏/即时通讯场景应该使用长连接；如：老师端和学生端的即时通讯教学软件； 最经典的案例是：数据库使用的连接。这里需要合理的设计keep-alive参数，在多少事件不适用以后就断开连接。

- 短连接：适用于并发量大且用户不需要频繁的交互式操作时，比如简单的请求网页。

###  HTTP 和 HTTPS 的区别？

端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

#### http的安全问题
1. 使用明文进行通信，内容可能被窃听
2. 无法验证通信方身份，可能被顶替
3. 无法验证报文的完整性。

#### https
http存在安全性问题：明文通信，容易被窃听；无法验证对方身份；无法验证报文完整

https使用ssl加密。可以防窃听，防伪装，防窜干。使用非对称密钥加密传输中的密钥，并且使用对称密钥加密进行通信。

加密过程：
![在这里插入图片描述](https://img-blog.csdnimg.cn/2021031122025312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)

缺点：成本高，传输效率低。
#### 数据签名与数字证书
> 数字签名

在非对称加密的基础上实现的。 发送方在对传输内容进行hash，得到内容摘要，然后使用私钥对传输内容进行加密。 这部分内容就是数字签名，然后将数字签名附在传输内容的后面。 同时对整个内容进行加密。

接受方使用公钥进行解密以后，得到数字签名，并对文本内容进行hash，比对与解密后的数字签名是否一致。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成"数字证书"

> 数字证书

数字证书是由可信机构发布的一个认证，保存了某个服务器的公钥。
### http1.0 1.1 2.0 区别

http1.1: 采用了长连接和管程的方法。另外，增加了Host域，在URL中额外传递了主机名。增加了缓存处理。

http2.0：头部数据压缩，HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。还用 Huffman 编码对首部字段进行压缩；多路复用做到同一个连接并发处理多个请求；服务器推送，HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。

### HTTP的长短连接
在HTTP/1.0中默认使用短连接。Http在1.1以后可以长连接(keep-alive)或者管线化，长连接是不用每次http请求都要建立tcp，而是在一个tcp中多次请求http；管线化是可以在tcp链接以后，一次性发很多个请求，然后服务器慢慢响应。

#### 长短连接的使用场景
长连接可以理解为整个通讯的过程。例如:client和server只用一个Socket，从而保持长期的通讯连接；短链接可以理解为每次client向Socket发送请求都会新建一个Socket,当处理完一个请求时就直接关闭掉Socket；
## http缓存
可以通过代理服务器缓存或者客户端浏览器缓存的方法，降低服务器压力和延迟。

http1.1中通过 Cache-Control 首部字段来控制缓存。并且可以指定缓存过期策略。

### Cookie的作用是什么?和Session有什么区别？
http是不保存状态的。因此需要cookie，在第一次连接以后服务端给客户端返回一个cookie，要求下次再请求就再请求头上加上cookie。

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

Cookie 一般用来保存用户信息 服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。


#### 浏览器禁用cookie怎么办
此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 **URL 重写技术，将 Session ID 作为 URL 的参数进行传递**。


## http的服务器
> 代理 
- 缓存代理，可以减少网络带宽的流量，当请求过来时候直接返回数据不用去源服务器请求。
- 透明代理，转发请求或者响应不会报文进行任何的加工。
> 网关
将http请求转化为其他协议通信。
> 隧道
建立一个安全的链接，ssl。

## 负责域名解析的DNS
DNS服务也是位于应用层的协议。提供域名到IP地址的解析，两者可以相互转换。

**Q: DNS解析的时候都发生了什么？**

### DNS解析过程
DNS解析默认是一个递归查询的过程。首先在**本地域名服务器**中查询IP地址，如果没有找到的情况下，本地域名服务器会向**根域名服务器**发送一个请求，如果根域名服务器也不存在该域名时，本地域名会向**com顶级域名服务器**发送一个请求，依次类推下去。直到最后**本地域名服务器得到google的IP地址并把它缓存到本地，供下次查询使用**。

从上述过程中，可以看出网址的解析是一个从右向左的过程: com -> google.com -> www.google.com。但是你是否发现少了点什么，根域名服务器的解析过程呢？事实上，真正的网址是www.google.com.，并不是我多打了一个.，这个.对应的就是根域名服务器，默认情况下所有的网址的最后一位都是.，既然是默认情况下，为了方便用户，通常都会省略，浏览器在请求DNS的时候会自动加上，所有网址真正的解析过程为: . -> .com -> google.com. -> www.google.com.。

**一般的 主机 向本地域名服务器的查询使用递归查询，本地域名服务器向根域名服务器查询使用迭代查询**

DNS**递归**名称解析： 在DNS递归名称解析中，当所配置的本地名称服务器解析不了时，后面的查询工作是由**本地名称服务器**替代DNS客户端进行的（以“本地名称服务器”为中心），只需要本地名称服务器向DNS客户端返回最终的查询结果即可。

DNS**迭代**名称解析：的所有查询工作全部是DNS客户端自己进行（以“DNS客户端”自己为中心）。在条件之一满足时就会采用迭代名称解析方式：
  1. 在查询本地名称服务器时，如果客户端的请求报文中没有申请使用递归查询，即在DNS请求报头部的RD字段没有置1。相当于说“你都没有主动要求我为你进行递归查询，我当然不会为你工作了”。

 2. 客户端在DNS请求报文中申请使用的是递归查询（也就是RD字段置1了），但在所配置的本地名称服务器上是禁用递归查询（DNS服务器一般默认支持递归查询的），即在应答DNS报文头部的RA字段置0。

它使用的是 UDP协议，原因是性能更好，查询时间更短，如果发生数据丢失，重传一个就好了，不需要建立连接 

>底层使用的UDP或者TCP。DNS服务器间进行域传输的时候用TCP 53。客户端查询DNS服务器时用 UDP 53。
### DNS优化
  * DNS缓存，多级缓存，不用真的每次都查找。
  * DNS负载均衡，DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。大家耳熟能详的CDN(Content Delivery Network)就是利用DNS的重定向技术，DNS服务器会返回一个跟用户最接近的点的IP地址给用户，CDN节点的服务器负责响应用户的请求，提供所需的内容。



# 传输层（TCP，UDP）

- 复用：把操作系统的多个进程利用一个传输层接口发送信息；
- 分发：把收到的信息利用传输层接口分发到操作系统的不同进程。



## TCP协议确保可靠
位于传输层。可以提供可靠的字节流服务，将大块的数据分割成以报文段为单位的数据包进行管理。

特点：特点是面向连接，基于报文段传输，能够保证消息可靠交付的协议；

TCP 用主机的 IP 地址加上主机上的端口号作为 TCP 连接的端点。这样的端点就叫做**套接字**（socket）或插口。套接字用（IP 地址：端口号）来表示。每一条 TCP 连接唯一被通信两端的两个端点所确定。


## TCP的三次握手与四次挥手
* 为何TCP要有端口？ 相当于外卖的手机号，外卖送到了需要分发给具体的用户。也就是给不同的进程使用。

### 三次握手的流程

![在这里插入图片描述](https://img-blog.csdnimg.cn/4febdad8652d457f870ea42d9bef7960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)


1. 客户端（SYN-SENT） –> 发送带有 **SYN=1**, seq=x,ack=0 的数据包 –> 服务端(LISTEN)
2. 服务端 (SYN-RECVD)–> 发送带有 **SYN=1 ACK=1**, 确认号ack=x+1, 序号seq=y 数据包 –> 客户端
3. 客户端（Established） –> 发送带有带有 **ACK=1**, seq=x+1, ack=y+1 标志的数据包 –> 服务端(Established)

### 三次握手的原因
双方都需要确认对方的发送和接受功能正常。第一次时候，服务端确认客户端的发送正常，自己的接受正常。第二次，服务端确认自己的发送正常，接受正常，服务端的接受正常，发送正常。第三次，服务端确认客户端的接受正常，自己的发送正常。

同时第三次握手，还可以避免失效(比如过期的请求)的连接请求到达服务器，让服务器错误的打开连接。

#### 什么是SYN攻击
在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 SYN_RCVD 状态。当收到 ACK 后，服务器才能转入 ESTABLISHED 状态.

SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。

>检测SYN攻击
当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击.在Linux下可以如下命令检测是否被Syn攻击`netstat -n -p TCP | grep SYN_RECV`

>防范
1. 使用网关超时设置 
2. 使用网关代理，代理在建立连接以后再给服务器。

## 四次挥手
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210306114541270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)

1. 客户端发送链接释放报文，**FIN=1**,seq=u (FIN-WIAT-1)
2. 服务端接受请求，发出确认**ACK=1**, seq=v, ack=u+1。此时TCP半关闭，客户端不再发送数据，但是服务端仍然可以发送。(CLOSE-WAIT)
3. 当服务端结束发送以后，发送链接释放报文，FIN=1，ACK=1, seq=w, ack=u+1;(LAST-ACK)
4. 客户端收到以后，发出确认 ACK=1, seq=u+1, ack=w+1。并且进入等待，等待2MSL（最大报文存活时间）保证网络无报文的了再释放连接。(TIME-WAIT)
5. 服务端收到确认释放连接。

注意两个阶段：服务器的`CLOSE_WAIT`和客户端的`TIME_WAIT`。服务器的`CLOSE_WAIT`表示此时服务器端只发送不再接收。客户端`TIME_WAIT`为保证最后一个报文能到达且让网络中其中的报文失效。

### 最后为何等待2MSL
所谓的2MSL是两倍的MSL(Maximum Segment Lifetime/最大报文段生存时间)。

1. 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。

2. 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。



## TCP如何保证可靠传输
1. 分割，排序编号。 应用数据被分割成 TCP 认为最适合发送的数据块。TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和**： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制**： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制**： 当网络拥塞时，减少数据的发送。
7. **ARQ协议**： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。连续ARQ协议可以维护一个窗口，窗口内的内容都是按序发送的，不需要等到确认。接收方采用累计按序确认，对最后一个进行确认即可。
8. **超时重传**： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 停止等待和连续ARQ协议
ARQ包括停止等待ARQ协议和连续ARQ协议。
* 停止等待ARQ协议

停止等待协议是为了实现可靠传输的，它的基本原理就是**每发完一个分组就停止发送，等待对方确认**（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。

在停止等待协议中，若接收方收到**重复分组，就丢弃该分组，但同时还要发送确认。**

* 连续 ARQ 协议
连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。**接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。**


### 滑动窗口和流量控制
TCP 利用**滑动窗口实现流量控制**。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 **接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率**。将窗口字段设置为 0，则发送方不能发送数据。

窗口维护了以后需要发送的序列。接受段确认以后，就可以移动。否则超时以后重发。

### 拥塞控制

拥塞是一个全局问题，设计全部的主机和路由。流量控制是端到端的问题。

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。

TCP的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。


- 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。**cwnd初始值为1，每经过一个传播轮次，cwnd加倍**。
    
- 拥塞避免： 设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。ssthresh = cwnd / 2，然后重新执行慢开始。

- 快重传与快恢复： 在 TCP/IP 中，快速重传和恢复（FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机**接收到三个重复确认**，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。**有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。**当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210601222249652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)

## TCP的状态机
![](https://img-blog.csdn.net/20140410152125734?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2hlbmdfZmFuZ2FuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## UDP
特点是无连接，基于用户数据报传输，不保证消息可靠交付，只尽 "最大努力交付"。
### TCP和UDP的比较
- TCP是面向连接的服务，再传输数据之前必须建立连接，再数据传输结束必须释放连接。TCP是保证交付的连接方式。 一般用于文件传输、发送和接收邮件、远程登录等场景。传输方式是面向字节流的因此可能导致粘包的情况。
- UDP再传输之前不需要建立连接，再收到UDP报文以后不需要给出任何确认。也不提供可靠交付，使用于即时通信，视频等。传输是面向报文的，不会发生沾包。
### UDP想要实现可靠性传输怎么办
传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了**应用层**。

实现**确认机制、重传机制、窗口确认机制**。
## 什么TCP的粘包

在socket网络编程中，都是端到端通信，由客户端端口+服务端端口+客户端IP+服务端IP+传输协议组成的五元组可以明确的标识一条连接。在TCP的socket编程中，发送端和接收端都有成对的socket。发送端为了将多个发往接收端的包，更加高效的的发给接收端，于是**采用了优化算法（Nagle算法），将多次间隔较小、数据量较小的数据，合并成一个数据量大的数据块，然后进行封包**。那么这样一来，接收端就必须使用高效科学的拆包机制来分辨这些数据。

> Q：什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。
### 造成TCP粘包的原因

（1）发送方原因

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

  - 只有上一个分组得到确认，才会发送下一个分组
  - 收集多个小分组，在一个确认到来时一起发送

**Nagle算法造成了发送方可能会出现粘包问题**

（2）接收方原因

TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，**TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组**。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

### 什么时候需要处理粘包现象？

如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象。

如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了。

### 如何处理粘包现象？

（1）发送方

对于发送方造成的粘包问题，可以**通过关闭Nagle算法**来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：**循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成**。但是如何判断每条数据的长度呢？

* **格式化数据**：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
  
* **发送长度**：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。

## UDP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了**基于流的传输**，基于流的传输不认为消息是一条一条的，**是无保护消息边界**的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是**面向消息传输**的，是**有保护消息边界**的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。

## TCP/UDP首部
![在这里插入图片描述](https://img-blog.csdnimg.cn/4dc309e2d43144a39f2904764f103473.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)


>TCP

源端口号和目的端口号：再加上Ip首部的源IP地址和目的IP地址可以唯一确定一个TCP连接

32位序号：表示一次tcp通信过程（从建立连接到断开）过程中某一次传输方向上的字节流的每个字节的编号。假定主机A和B进行tcp通信，A传送给B一个tcp报文段中，序号值被系统初始化为某一个随机值ISN，那么在该传输方向上（从A到B），后续的所有tcp报文断中的序号值都会被设定为ISN加上该报文段所携带数据的第一个字节在整个字节流中的偏移。例如某个TCP报文段传送的数据是字节流中的第1025~2048字节，那么该报文段的序号值就是ISN+1025。

32位确认号：用作对另一方发送的tcp报文段的响应。其值是收到对方的tcp报文段的序号值＋1。假定主机A和B进行tcp通信，那么A发出的tcp报文段不但带有自己的序号，也包含了对B发送来的tcp报文段的确认号。反之也一样。
# 网络层（IP协议，ARP协议）
## IP协议提供传输
位于网络层。
IP地址指明了节点被分配到的地址，MAC地址是网卡所属的固定地址。使用ARP协议，根据对方的IP地址反查出对应的MAC地址。主要是连接两台主机，具体的主机的进程之间的通信时传


## 网络层的ARP协议（ip->mac）
主机 A 与主机 B 进行通信，需要获取其 MAC 地址，基本流程如下：

  - 主机 A 以广播形式向网络中所有主机发送 ARP 请求，请求包中包含了目标 IP 地址 192.168.1.2。
  - 主机 B 接收到请求，发现自己就是主机 A 要找的主机，返回响应，响应包中包含自己的 MAC 地址。


为加速，会有**ARP缓存**。

1) 主机 A 在本机 ARP 缓存中检查主机 B 的匹配 MAC 地址。

2) 如果在 ARP 缓存中没有找到主机 B 的 IP 地址及对应的 MAC 地址，它将询问主机 B 的 MAC 地址，从而将 ARP 请求帧广播到本地网络上的所有主机。源主机 A 的 IP 地址和 MAC 地址都包括在 ARP 请求中。

3) 本地网络上的每台主机都接收到 ARP 请求，并且检查是否与自己的 IP 地址匹配。如果主机发现请求的 IP 地址与自己的 IP 地址不匹配，它将丢弃 ARP 请求。主机 B 确定 ARP 请求中的 IP 地址与自己的 IP 地址匹配，则将主机 A 的 IP 地址和 MAC 地址映射添加到本地 ARP 缓存中。

4) 主机 B 将包含自身 MAC 地址的 ARP 回复消息直接发送给主机 A。

5) 当主机 A 收到从主机 B 发来的 ARP 回复消息时，会用主机 B 的 IP 地址和 MAC 地址更新 ARP 缓存。
6) 主机 B 的 MAC 地址一旦确定，主机 A 就能向主机 B 发送 IP 数据包。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。 



## Ping命令的过程
假设机器Aping机器B.

1. 如果ping的是一个主机名,需要先进行**DNS解析**,得到具体ip地址.
2. **ICMP协议**打包这个数据包和机器B的IP地址转交给IP协议层。
3. 然后我们需要通过**ARP协议**,获取到mac地址.如果这个IP的mac地址在本地缓存中查询不到.需要发送广播请求.
4. 主机A发送ICMP数据包到主机B,B予以回复.

步骤a：应用程序ping会判断发送的是主机名还是IP地址，通过DNS协议,将主机名转换成一个32位的IP地址。

步骤b：ICMP协议打包这个数据包和机器B的IP地址转交给IP协议层。

步骤c：由于主机A和主机B在同一个局域网内,必须把目标主机的IP地址转换为48位的硬件地址,即调用ARP协议,在局域网内发送ARP请求广播,查找主机B的硬件地址。

步骤d：主机B的ARP协议层接收到主机A的ARP请求后,将本机的硬件地址填充到合适的位置后,发送ARP应答到主机A.

步骤e：主机A发送ICMP数据包到主机B.

步骤f：主机B接收到主机A的ICMP包,发送响应包。

步骤g：主机A接收到主机B的ICMP响应包。

# 在浏览器输入url会什么过程。

![](https://camo.githubusercontent.com/c757ddcd23ab760aabb28c35adeadb49fe872f47f0dfb3ed5e4144ca9aa704cb/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d31312f75726ce8be93e585a5e588b0e5b195e7a4bae587bae69da5e79a84e8bf87e7a88b2e6a7067)

1. DNS解析，首先访问local dns server，如果有缓存直接返回。否则local DNS迭代查找ip地址，并缓存
2. TCP连接，三次握手建立连接。
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束，四次挥手


## 跨域请求
因为浏览器的同源策略规定某域下的客户端在没明确授权的情况下，不能读写另一个域的资源。而在实际开发中，前后端常常是相互分离的，并且前后端的项目部署也常常不在一个服务器内或者在一个服务器的不同端口下。**前端想要获取后端的数据，就必须发起请求，如果不做一些处理，就会受到浏览器同源策略的约束。后端可以收到请求并返回数据，但是前端无法收到数据。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/7deca45dab6d4e51976919987204e6d3.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)
